{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Lesson: Data Sources\n",
                "\n",
                "In data science, the first step is always getting the data. In this lesson, we'll explore three of the most common ways to bring data into your Python environment using the `pandas` library.\n",
                "\n",
                "1. **CSV Files (Comma Separated Values)**\n",
                "2. **Google Sheets**\n",
                "3. **Webpages (HTML Tables)**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "csv-section",
            "metadata": {},
            "source": [
                "## 1. CSV Files\n",
                "\n",
                "CSV files are the most common format for data exchange. They are simple text files where each piece of data is separated by a comma. You can load them from a local file on your computer or directly from a URL on the internet."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "csv-url",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Loading from a URL (e.g., Indiana Pacers 2024-2025 player stats)\n",
                "csv_url = \"https://raw.githubusercontent.com/Data-Dunkers/data/refs/heads/main/NBA/team/2024-2025/IND_2024-2025_players.csv\"\n",
                "df_csv = pd.read_csv(csv_url)\n",
                "df_csv.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "gsheets-section",
            "metadata": {},
            "source": [
                "## 2. Google Sheets\n",
                "\n",
                "Google Sheets is a popular tool for collaborative data collection. To load data from a Google Sheet, you don't need to download it; you can read it directly into Python by following these steps:\n",
                "\n",
                "1. **Share the Sheet**: Click the **Share** button and set the access to **\"Anyone with the link\"**.\n",
                "2. **Copy the Link**: Copy the URL of your Google Sheet.\n",
                "3. **Modify the URL**: Replace the end of the URL (everything after the last `/`) with `export?format=csv`.\n",
                "\n",
                "**Example Conversion:**\n",
                "*   **Original**: `.../d/1ZULKhYzsMd4eYwiprsyGgE9Df3gaVtO8WRalUQDn-xE/edit#gid=0`\n",
                "*   **Modified**: `.../d/1ZULKhYzsMd4eYwiprsyGgE9Df3gaVtO8WRalUQDn-xE/export?format=csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gsheets-example",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Loading a public Google Sheet with sample basketball data\n",
                "sheet_url = \"https://docs.google.com/spreadsheets/d/1ZULKhYzsMd4eYwiprsyGgE9Df3gaVtO8WRalUQDn-xE/export?format=csv\"\n",
                "df_sheet = pd.read_csv(sheet_url)\n",
                "df_sheet.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "web-scraping-section",
            "metadata": {},
            "source": [
                "## 3. Webpages (HTML Tables)\n",
                "\n",
                "Sometimes data is displayed in a table on a website, like on Wikipedia or a sports news site. You can use `pd.read_html()` to automatically scan a webpage for all its tables and return them as a list of DataFrames."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "web-scraping-example",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Scraping a table from Wikipedia\n",
                "wiki_url = \"https://en.wikipedia.org/wiki/Indiana_Pacers\"\n",
                "tables = pd.read_html(wiki_url)\n",
                "\n",
                "# Show the first table found on the page\n",
                "tables[0].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "reflection-questions",
            "metadata": {},
            "source": [
                "## Reflection Questions\n",
                "\n",
                "1. **Which data source felt the easiest to use? Why?**\n",
                "2. **What are some risks of using `pd.read_html()` to get data from a website?**\n",
                "3. **When would you use a Google Sheet instead of a simple CSV file?**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}