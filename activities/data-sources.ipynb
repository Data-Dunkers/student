{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Lesson: Data Sources\n",
                "\n",
                "In data science, the first step is always getting the data. In this lesson, we'll explore three of the most common ways to bring data into your Python environment using the `pandas` library.\n",
                "\n",
                "1. **CSV Files (Comma Separated Values)**\n",
                "2. **Google Sheets**\n",
                "3. **Webpages (HTML Tables)**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "csv-section",
            "metadata": {},
            "source": [
                "## 1. CSV Files\n",
                "\n",
                "CSV files are the most common format for data exchange. They are simple text files where each piece of data is separated by a comma. You can load them from a local file on your computer or directly from a URL on the internet."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "csv-url",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Loading from a URL (e.g., Indiana Pacers 2024-2025 player stats)\n",
                "csv_url = \"https://raw.githubusercontent.com/Data-Dunkers/data/refs/heads/main/NBA/team/2024-2025/IND_2024-2025_players.csv\"\n",
                "df_csv = pd.read_csv(csv_url)\n",
                "df_csv.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "gsheets-section",
            "metadata": {},
            "source": [
                "## 2. Google Sheets\n",
                "\n",
                "Google Sheets is a popular tool for collaborative data collection. To load data from a Google Sheet into your notebook, follow these steps:\n",
                "\n",
                "1. Open your Google Sheet.\n",
                "2. Go to **File > Share > Publish to the web**.\n",
                "3. Select \"Link\", ensure \"Entire Document\" and \"Comma-separated values (.csv)\" are selected.\n",
                "4. Click **Publish** and copy the generated link.\n",
                "\n",
                "Once you have the link, you can use `pd.read_csv()` just like with a standard CSV file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gsheets-example",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: A published Google Sheet with sample basketball data\n",
                "sheet_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSPh7v3Y0R3_f3eLueK6Bq-L-uU6E8A8pL6kS1z_Y3x_Y8_X_Z_Y_X_Z_Y_X/pub?output=csv\"\n",
                "# Note: The link above is a placeholder; replace it with your own published link.\n",
                "try:\n",
                "    df_sheet = pd.read_csv(sheet_url)\n",
                "    print(\"Successfully loaded Google Sheet.\")\n",
                "except Exception as e:\n",
                "    print(f\"Could not load sheet: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "web-scraping-section",
            "metadata": {},
            "source": [
                "## 3. Webpages (HTML Tables)\n",
                "\n",
                "Sometimes data is displayed in a table on a website, like on Wikipedia or a sports news site. You can use `pd.read_html()` to automatically scan a webpage for all its tables and return them as a list of DataFrames."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "web-scraping-example",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Scraping a table from Wikipedia\n",
                "wiki_url = \"https://en.wikipedia.org/wiki/Indiana_Pacers\"\n",
                "tables = pd.read_html(wiki_url)\n",
                "\n",
                "# Show the first table found on the page\n",
                "tables[0].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "reflection-questions",
            "metadata": {},
            "source": [
                "## Reflection Questions\n",
                "\n",
                "1. **Which data source felt the easiest to use? Why?**\n",
                "2. **What are some risks of using `pd.read_html()` to get data from a website?**\n",
                "3. **When would you use a Google Sheet instead of a simple CSV file?**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}